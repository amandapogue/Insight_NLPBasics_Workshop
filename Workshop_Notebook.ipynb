{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of NLP\n",
    "A short workshop of NLP techniques for those with little or no experience with NLP.\n",
    "\n",
    "## What is NLP?\n",
    "* NLP stands for Natural Language Processing, and the field is concerned with the ability to use computers to manipulate text data. \n",
    "* Researchers in computational linguistics are focused in three areas: NLP, NLG (natural language generation) and NLU (natural language understanding)\n",
    "* NLP researchers tend to study and word on problems that include: \n",
    "  * parsing strings into individual paragraphs, sentences, words, morphemes, etc\n",
    "  * finding grammatical relations and structures\n",
    "  * identifying entities\n",
    "  * comparing strings\n",
    "  * feature extractions, such as: sentiments, topics, etc\n",
    "  \n",
    "Today we're going to cover some of the basics in NLP. Including why and how to preprocess text data\n",
    "\n",
    "First we'll read in some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import data \n",
    "wine_data = pd.read_csv(\"data/winemag-data_first150k.csv\", encoding = 'utf8')\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any rows where we have no description\n",
    "wine_data = wine_data[pd.notnull(wine_data['description'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few quick initial thoughts about Computational Linguistics:\n",
    "* computers know nothing about words\n",
    "  * as humans we know that \"US\", \"USA\", \"us\", \"usa\", and \"u.s.a.\" are all referencing the same place, but computers can only compare things that are identical\n",
    "  * if we want to be able to compare words, then we have to make the words as uniform as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA and usa are the same word: False\n",
      "u.s.a. and usa are the same word: False\n",
      "Amanda and amanda are the same word: False\n"
     ]
    }
   ],
   "source": [
    "# In case you don't believe me:\n",
    "print (\"USA and usa are the same word:\" , \"USA\"==\"usa\")\n",
    "print (\"u.s.a. and usa are the same word:\" , \"u.s.a.\"==\"usa\")\n",
    "print(\"Amanda and amanda are the same word:\", \"Amanda\"==\"amanda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text\n",
    "\n",
    "When working with text data, the goal is to process (remove, filter, and combine) the text in such a way that informative text is preserve and munged into a form that models can better understand.  After looking at our raw text, we know that there are a number of textual attributes that we will need to address before we can ultimately represent our text as quantified features. \n",
    "\n",
    "A common first step is to handle [string encoding](http://kunststube.net/encoding/) and formatting issues.  Often it is easy to address the character encoding and mixed capitalization using Python's built-in functions. For our wine example, we will convert everything to UTF-8 encoding and convert all letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  This tremendous 100% varietal wine hails from Oakville and was aged over three years in oak. Juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. Balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. Enjoy 2022–2030.\n",
      "Lower-cased:  this tremendous 100% varietal wine hails from oakville and was aged over three years in oak. juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. enjoy 2022–2030.\n"
     ]
    }
   ],
   "source": [
    "# for simplicity we can look at what this does for a single row:\n",
    "\n",
    "wine1 = wine_data.description.iloc[0]\n",
    "\n",
    "print (\"Original: \", wine1)\n",
    "print(\"Lower-cased: \", wine1.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing\n",
    "In order to process text, it must be deconstructed into its constituent elements through a process termed *tokenization*. Often, the *tokens* yielded from this process are simply individual words in a document.  In certain cases, it can be useful to tokenize stranger objects like emoji or parts of html (or other code).\n",
    "\n",
    "A simplistic way to tokenize text relies on white space, such as in <code>nltk.tokenize.WhitespaceTokenizer</code>. Relying on white space, however, does not take *punctuation* into account, and depending on this some tokens will include punctuation  and will require further preprocessing (e.g. 'account,'). Depending on your data, the punctuation may provide meaningful information, so you will want to think about whether it should be preserved or if it can be removed.\n",
    "\n",
    "Tokenization is particularly challenging in the biomedical field, where many phrases contain substantial punctuation (parentheses, hyphens, etc.) that can't necessarily be ignored. Additionally, negation detection can be critical in this context which can provide an additional preprocessing challenge.\n",
    "\n",
    "NLTK contains many built-in modules for tokenization, such as <code>nltk.tokenize.WhitespaceTokenizer</code> and <code>nltk.tokenize.RegexpTokenizer</code>. It surprisingly also has a module specifically for deal with Twitter data, <code>nltk.tokenize.casual.TweetTokenizer</code> which just has a few features related to handling twitter handles.\n",
    "\n",
    "SpaCy also has built in modules to deal with tokenization. Below we'll look at a few different kinds of tokenizers. \n",
    "\n",
    "See also:\n",
    "\n",
    "[The Art of Tokenization](https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en)<br>\n",
    "[Negation's Not Solved: Generalizability Versus Optimizability in Clinical Natural Language Processing](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4231086/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace Tokenizer\n",
    "One possible method for tokenizing. However, this particular tool identifies words by using whitespace. It thus considers punctuation to be part of a word at times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'tremendous', '100%', 'varietal', 'wine', 'hails', 'from', 'oakville', 'and', 'was', 'aged', 'over', 'three', 'years', 'in', 'oak.', 'juicy', 'red-cherry', 'fruit', 'and', 'a', 'compelling', 'hint', 'of', 'caramel', 'greet', 'the', 'palate,', 'framed', 'by', 'elegant,', 'fine', 'tannins', 'and', 'a', 'subtle', 'minty', 'tone', 'in', 'the', 'background.', 'balanced', 'and', 'rewarding', 'from', 'start', 'to', 'finish,', 'it', 'has', 'years', 'ahead', 'of', 'it', 'to', 'develop', 'further', 'nuance.', 'enjoy', '2022–2030.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "ws_tokenizer = WhitespaceTokenizer()\n",
    "\n",
    "# tokenize example review\n",
    "wine1_ws = nyt_ws_tokens = ws_tokenizer.tokenize(wine1.lower())\n",
    "print(wine1_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Tokenization\n",
    "\n",
    "By applying the regular expression tokenizer we can more highly tune our tokenizer to yield the types of tokens useful for our data.  Here we return a list of word tokens without punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'tremendous', '100', 'varietal', 'wine', 'hails', 'from', 'oakville', 'and', 'was', 'aged', 'over', 'three', 'years', 'in', 'oak', 'juicy', 'red', 'cherry', 'fruit', 'and', 'a', 'compelling', 'hint', 'of', 'caramel', 'greet', 'the', 'palate', 'framed', 'by', 'elegant', 'fine', 'tannins', 'and', 'a', 'subtle', 'minty', 'tone', 'in', 'the', 'background', 'balanced', 'and', 'rewarding', 'from', 'start', 'to', 'finish', 'it', 'has', 'years', 'ahead', 'of', 'it', 'to', 'develop', 'further', 'nuance', 'enjoy', '2022', '2030']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "re_tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# tokenize example review\n",
    "wine1_re = re_tokenizer.tokenize(wine1.lower())\n",
    "print(wine1_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy\n",
    "SpaCy is a kind of cool package that can tokenize words, lemmatize, find named entities, etc. So, you can imagine it as an alternative to NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this tremendous 100% varietal wine hails from oakville and was aged over three years in oak. juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background. balanced and rewarding from start to finish, it has years ahead of it to develop further nuance. enjoy 2022–2030.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "print(nlp(wine1.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "tremendous\n",
      "100\n",
      "%\n",
      "varietal\n",
      "wine\n",
      "hails\n",
      "from\n",
      "oakville\n",
      "and\n",
      "was\n",
      "aged\n",
      "over\n",
      "three\n",
      "years\n",
      "in\n",
      "oak\n",
      ".\n",
      "juicy\n",
      "red\n",
      "-\n",
      "cherry\n",
      "fruit\n",
      "and\n",
      "a\n",
      "compelling\n",
      "hint\n",
      "of\n",
      "caramel\n",
      "greet\n",
      "the\n",
      "palate\n",
      ",\n",
      "framed\n",
      "by\n",
      "elegant\n",
      ",\n",
      "fine\n",
      "tannins\n",
      "and\n",
      "a\n",
      "subtle\n",
      "minty\n",
      "tone\n",
      "in\n",
      "the\n",
      "background\n",
      ".\n",
      "balanced\n",
      "and\n",
      "rewarding\n",
      "from\n",
      "start\n",
      "to\n",
      "finish\n",
      ",\n",
      "it\n",
      "has\n",
      "years\n",
      "ahead\n",
      "of\n",
      "it\n",
      "to\n",
      "develop\n",
      "further\n",
      "nuance\n",
      ".\n",
      "enjoy\n",
      "2022–2030\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# you can use spacy to get individual tokens:\n",
    "for token in nlp(wine1.lower()):\n",
    "    print (token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this tremendous 100% varietal wine hails from oakville and was aged over three years in oak.\n",
      "juicy red-cherry fruit and a compelling hint of caramel greet the palate, framed by elegant, fine tannins and a subtle minty tone in the background.\n",
      "balanced and rewarding from start to finish, it has years ahead of it to develop further nuance.\n",
      "enjoy 2022–2030.\n"
     ]
    }
   ],
   "source": [
    "# you can also get sentences usinf SpaCy\n",
    "for sent in nlp(wine1.lower()).sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final thoughts on tokenization:\n",
    "Which tokenizer you use depends on what you are going to need for your model ultimately. You should think about what is the most appropriate choice. In some senses it it fine to do something like lowercase, and then get individual words without punctuation, but there are other circumstances when this might not be helpful. For example, imagine if you were trying to identify questions in your "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:insight]",
   "language": "python",
   "name": "conda-env-insight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
